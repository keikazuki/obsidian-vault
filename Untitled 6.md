You can “multiply” your existing rows by joining them with a set of numbers generated by PostgreSQL’s `generate_series` function. For example, suppose you want to duplicate all rows returned by

```sql
SELECT * FROM dashboard_annotationtracksample WHERE track_id = 45;
```

until you have 100,000 rows in total. (Make sure you know how many rows the query returns originally so you can compute the multiplication factor.) For instance, if your query returns 20 rows, you’d need to insert 5,000 copies of each row because:

  20 rows × 5,000 copies = 100,000 rows

One way to do this is by using an `INSERT ... SELECT` query with a `CROSS JOIN` to `generate_series`. For example:

```sql
INSERT INTO dashboard_annotationtracksample
  (data, status, created_at, annotated_at, validated_at, updated_at,
   annotated_by_id, track_id, validated_by_id)
SELECT 
    t.data,
    t.status,
    t.created_at,
    t.annotated_at,
    t.validated_at,
    t.updated_at,
    t.annotated_by_id,
    t.track_id,
    t.validated_by_id
FROM dashboard_annotationtracksample AS t
CROSS JOIN generate_series(1, 5000) AS gs
WHERE t.track_id = 45;
```

### How This Works

- **`generate_series(1, 5000)`** produces 5,000 rows (one for each integer from 1 to 5000).
- The **`CROSS JOIN`** multiplies every row from your original query (those with `track_id = 45`) by 5,000.
- Since the `id` column is defined as an identity column, PostgreSQL automatically assigns a new unique `id` for every inserted row.

### Adjusting the Multiplication Factor

If your original query returns a different number of rows (say, _N_ rows), then you need to calculate the duplication factor as:

  **Factor** = Ceiling(100,000 / _N_)

and then use that factor in `generate_series(1, factor)`.

### A Few Cautions

- **Backup or test on a non‐production copy first.** Running an insert like this will add a large number of rows.
- **Foreign Key Constraints:** If any columns (such as `annotated_by_id`, `validated_by_id`, or even `track_id`) reference other tables, be sure that duplicating rows won’t cause integrity problems.
- **Repeated Runs:** Ensure you run the script only once (or adjust your logic) to avoid overshooting your target of 100,000 rows.

This approach should help you quickly generate 100,000 rows by duplicating your existing records.